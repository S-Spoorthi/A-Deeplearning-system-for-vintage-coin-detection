{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95bebb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fcb3cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5150 images belonging to 13 classes.\n",
      "Found 1283 images belonging to 13 classes.\n",
      "Found 724 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the train and test directories\n",
    "train_data_dir = 'D:/data_split/train'\n",
    "test_data_dir = 'D:/data_split/test'\n",
    "\n",
    "# Set the number of classes and image dimensions\n",
    "num_classes = 13\n",
    "image_size = (96, 96)\n",
    "batch_size = 8\n",
    "class_names = [\n",
    "    'Andorra_2019',\n",
    "    'Common',\n",
    "    'Lithuania_2021',\n",
    "    'Monaco_2015',\n",
    "    'Monaco_2016',\n",
    "    'Monaco_2017',\n",
    "    'Monaco_2018',\n",
    "    'Monaco_2019',\n",
    "    'SanMarino_2004',\n",
    "    'SanMarino_2005',\n",
    "    'Vatican_2004',\n",
    "    'Vatican_2005',\n",
    "    'Vatican_2006'\n",
    "]\n",
    "\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# Normalization for testing/validation\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data generators for loading the train and test images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=image_size,\n",
    "    classes = class_names,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    seed=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=image_size,\n",
    "    classes = class_names,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    seed=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=image_size,\n",
    "    classes = class_names,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    #seed=42,\n",
    "    shuffle=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a8ee1f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1179904   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 13)                3341      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,897,933\n",
      "Trainable params: 1,183,245\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "643/643 [==============================] - 458s 705ms/step - loss: 1.9294 - accuracy: 0.3526 - val_loss: 1.4550 - val_accuracy: 0.5594\n",
      "Epoch 2/100\n",
      "643/643 [==============================] - 497s 773ms/step - loss: 1.2180 - accuracy: 0.5708 - val_loss: 1.0371 - val_accuracy: 0.6578\n",
      "Epoch 3/100\n",
      "643/643 [==============================] - 486s 756ms/step - loss: 0.9409 - accuracy: 0.6836 - val_loss: 0.8498 - val_accuracy: 0.7352\n",
      "Epoch 4/100\n",
      "643/643 [==============================] - 486s 755ms/step - loss: 0.7917 - accuracy: 0.7260 - val_loss: 0.7778 - val_accuracy: 0.7547\n",
      "Epoch 5/100\n",
      "643/643 [==============================] - 492s 765ms/step - loss: 0.6877 - accuracy: 0.7546 - val_loss: 0.6940 - val_accuracy: 0.7977\n",
      "Epoch 6/100\n",
      "643/643 [==============================] - 452s 702ms/step - loss: 0.6270 - accuracy: 0.7802 - val_loss: 0.6358 - val_accuracy: 0.8008\n",
      "Epoch 7/100\n",
      "643/643 [==============================] - 401s 624ms/step - loss: 0.5626 - accuracy: 0.8030 - val_loss: 0.5491 - val_accuracy: 0.8445\n",
      "Epoch 8/100\n",
      "643/643 [==============================] - 407s 633ms/step - loss: 0.4977 - accuracy: 0.8201 - val_loss: 0.6012 - val_accuracy: 0.8023\n",
      "Epoch 9/100\n",
      "643/643 [==============================] - 408s 634ms/step - loss: 0.4768 - accuracy: 0.8292 - val_loss: 0.6388 - val_accuracy: 0.8148\n",
      "Epoch 10/100\n",
      "643/643 [==============================] - 406s 631ms/step - loss: 0.4659 - accuracy: 0.8339 - val_loss: 0.6010 - val_accuracy: 0.8266\n",
      "Epoch 11/100\n",
      "643/643 [==============================] - 406s 632ms/step - loss: 0.4050 - accuracy: 0.8512 - val_loss: 0.5617 - val_accuracy: 0.8391\n",
      "Epoch 12/100\n",
      "643/643 [==============================] - 408s 634ms/step - loss: 0.3785 - accuracy: 0.8623 - val_loss: 0.5196 - val_accuracy: 0.8500\n",
      "Epoch 13/100\n",
      "643/643 [==============================] - 406s 631ms/step - loss: 0.3683 - accuracy: 0.8611 - val_loss: 0.5378 - val_accuracy: 0.8539\n",
      "Epoch 14/100\n",
      "643/643 [==============================] - 405s 630ms/step - loss: 0.3736 - accuracy: 0.8631 - val_loss: 0.5574 - val_accuracy: 0.8555\n",
      "Epoch 15/100\n",
      "643/643 [==============================] - 405s 630ms/step - loss: 0.3437 - accuracy: 0.8769 - val_loss: 0.5735 - val_accuracy: 0.8430\n",
      "Epoch 16/100\n",
      "643/643 [==============================] - 407s 633ms/step - loss: 0.3327 - accuracy: 0.8816 - val_loss: 0.5281 - val_accuracy: 0.8570\n",
      "Epoch 17/100\n",
      "643/643 [==============================] - 404s 629ms/step - loss: 0.3113 - accuracy: 0.8806 - val_loss: 0.5874 - val_accuracy: 0.8648\n",
      "Epoch 18/100\n",
      "643/643 [==============================] - 404s 628ms/step - loss: 0.3261 - accuracy: 0.8765 - val_loss: 0.6189 - val_accuracy: 0.8438\n",
      "Epoch 19/100\n",
      "643/643 [==============================] - 406s 631ms/step - loss: 0.3422 - accuracy: 0.8740 - val_loss: 0.4840 - val_accuracy: 0.8586\n",
      "Epoch 20/100\n",
      "643/643 [==============================] - 407s 633ms/step - loss: 0.2848 - accuracy: 0.8952 - val_loss: 0.4439 - val_accuracy: 0.8719\n",
      "Epoch 21/100\n",
      "643/643 [==============================] - 408s 634ms/step - loss: 0.2754 - accuracy: 0.8981 - val_loss: 0.6564 - val_accuracy: 0.8406\n",
      "Epoch 22/100\n",
      "643/643 [==============================] - 408s 635ms/step - loss: 0.2990 - accuracy: 0.8915 - val_loss: 0.5480 - val_accuracy: 0.8570\n",
      "Epoch 23/100\n",
      "643/643 [==============================] - 405s 629ms/step - loss: 0.2672 - accuracy: 0.9002 - val_loss: 0.6034 - val_accuracy: 0.8391\n",
      "Epoch 24/100\n",
      "643/643 [==============================] - 407s 633ms/step - loss: 0.2616 - accuracy: 0.9043 - val_loss: 0.5302 - val_accuracy: 0.8555\n",
      "Epoch 25/100\n",
      "643/643 [==============================] - 411s 639ms/step - loss: 0.2463 - accuracy: 0.9100 - val_loss: 0.5352 - val_accuracy: 0.8750\n",
      "Epoch 26/100\n",
      "643/643 [==============================] - 404s 629ms/step - loss: 0.2802 - accuracy: 0.8971 - val_loss: 0.4848 - val_accuracy: 0.8609\n",
      "Epoch 27/100\n",
      "643/643 [==============================] - 409s 636ms/step - loss: 0.2450 - accuracy: 0.9068 - val_loss: 0.6120 - val_accuracy: 0.8602\n",
      "Epoch 28/100\n",
      "643/643 [==============================] - 436s 678ms/step - loss: 0.2641 - accuracy: 0.9026 - val_loss: 0.5070 - val_accuracy: 0.8695\n",
      "Epoch 29/100\n",
      "643/643 [==============================] - 454s 707ms/step - loss: 0.2489 - accuracy: 0.9055 - val_loss: 0.4677 - val_accuracy: 0.8758\n",
      "Epoch 30/100\n",
      "643/643 [==============================] - 23512s 37s/step - loss: 0.2494 - accuracy: 0.9053 - val_loss: 0.6895 - val_accuracy: 0.8359\n",
      "Epoch 31/100\n",
      "643/643 [==============================] - 418s 650ms/step - loss: 0.2515 - accuracy: 0.9090 - val_loss: 0.5910 - val_accuracy: 0.8727\n",
      "Epoch 32/100\n",
      "643/643 [==============================] - 414s 643ms/step - loss: 0.2191 - accuracy: 0.9191 - val_loss: 0.6300 - val_accuracy: 0.8492\n",
      "Epoch 33/100\n",
      "643/643 [==============================] - 416s 646ms/step - loss: 0.2456 - accuracy: 0.9135 - val_loss: 0.7288 - val_accuracy: 0.8469\n",
      "Epoch 34/100\n",
      "643/643 [==============================] - 412s 641ms/step - loss: 0.2150 - accuracy: 0.9187 - val_loss: 0.5808 - val_accuracy: 0.8711\n",
      "Epoch 35/100\n",
      "643/643 [==============================] - 292s 455ms/step - loss: 0.2523 - accuracy: 0.9063 - val_loss: 0.6719 - val_accuracy: 0.8773\n",
      "Epoch 36/100\n",
      "643/643 [==============================] - 292s 455ms/step - loss: 0.2028 - accuracy: 0.9240 - val_loss: 0.6013 - val_accuracy: 0.8430\n",
      "Epoch 37/100\n",
      "643/643 [==============================] - 319s 496ms/step - loss: 0.2158 - accuracy: 0.9207 - val_loss: 0.6090 - val_accuracy: 0.8617\n",
      "Epoch 38/100\n",
      "643/643 [==============================] - 358s 558ms/step - loss: 0.2448 - accuracy: 0.9088 - val_loss: 0.6351 - val_accuracy: 0.8633\n",
      "Epoch 39/100\n",
      "643/643 [==============================] - 353s 549ms/step - loss: 0.2062 - accuracy: 0.9226 - val_loss: 0.8454 - val_accuracy: 0.8383\n",
      "Epoch 40/100\n",
      "643/643 [==============================] - 342s 531ms/step - loss: 0.2342 - accuracy: 0.9135 - val_loss: 0.6304 - val_accuracy: 0.8727\n",
      "Epoch 41/100\n",
      "643/643 [==============================] - 327s 509ms/step - loss: 0.2266 - accuracy: 0.9185 - val_loss: 0.7352 - val_accuracy: 0.8508\n",
      "Epoch 42/100\n",
      "643/643 [==============================] - 325s 506ms/step - loss: 0.2112 - accuracy: 0.9222 - val_loss: 0.6432 - val_accuracy: 0.8602\n",
      "Epoch 43/100\n",
      "643/643 [==============================] - 32742s 51s/step - loss: 0.2055 - accuracy: 0.9236 - val_loss: 0.5804 - val_accuracy: 0.8617\n",
      "Epoch 44/100\n",
      "643/643 [==============================] - 317s 493ms/step - loss: 0.2212 - accuracy: 0.9191 - val_loss: 0.6432 - val_accuracy: 0.8500\n",
      "Epoch 45/100\n",
      "643/643 [==============================] - 298s 464ms/step - loss: 0.2191 - accuracy: 0.9207 - val_loss: 0.7291 - val_accuracy: 0.8523\n",
      "Epoch 46/100\n",
      "643/643 [==============================] - 314s 488ms/step - loss: 0.1835 - accuracy: 0.9356 - val_loss: 0.7052 - val_accuracy: 0.8680\n",
      "Epoch 47/100\n",
      "643/643 [==============================] - 332s 516ms/step - loss: 0.1933 - accuracy: 0.9253 - val_loss: 0.6585 - val_accuracy: 0.8578\n",
      "Epoch 48/100\n",
      "643/643 [==============================] - 310s 482ms/step - loss: 0.1790 - accuracy: 0.9343 - val_loss: 0.6020 - val_accuracy: 0.8695\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643/643 [==============================] - 302s 470ms/step - loss: 0.1920 - accuracy: 0.9269 - val_loss: 0.7294 - val_accuracy: 0.8656\n",
      "Epoch 50/100\n",
      "643/643 [==============================] - 292s 455ms/step - loss: 0.1806 - accuracy: 0.9325 - val_loss: 0.6562 - val_accuracy: 0.8477\n",
      "Epoch 51/100\n",
      "643/643 [==============================] - 294s 458ms/step - loss: 0.1921 - accuracy: 0.9265 - val_loss: 0.7313 - val_accuracy: 0.8562\n",
      "Epoch 52/100\n",
      "643/643 [==============================] - 318s 495ms/step - loss: 0.1792 - accuracy: 0.9339 - val_loss: 0.7323 - val_accuracy: 0.8641\n",
      "Epoch 53/100\n",
      "643/643 [==============================] - 307s 478ms/step - loss: 0.2188 - accuracy: 0.9148 - val_loss: 0.7916 - val_accuracy: 0.8531\n",
      "Epoch 54/100\n",
      "643/643 [==============================] - 344s 535ms/step - loss: 0.1855 - accuracy: 0.9360 - val_loss: 0.7659 - val_accuracy: 0.8719\n",
      "Epoch 55/100\n",
      "643/643 [==============================] - 346s 538ms/step - loss: 0.1938 - accuracy: 0.9280 - val_loss: 0.6898 - val_accuracy: 0.8695\n",
      "Epoch 56/100\n",
      "643/643 [==============================] - 326s 507ms/step - loss: 0.1886 - accuracy: 0.9294 - val_loss: 0.6430 - val_accuracy: 0.8734\n",
      "Epoch 57/100\n",
      "643/643 [==============================] - 294s 458ms/step - loss: 0.1793 - accuracy: 0.9333 - val_loss: 0.6508 - val_accuracy: 0.8687\n",
      "Epoch 58/100\n",
      "643/643 [==============================] - 295s 459ms/step - loss: 0.1746 - accuracy: 0.9393 - val_loss: 0.6878 - val_accuracy: 0.8633\n",
      "Epoch 59/100\n",
      "643/643 [==============================] - 295s 459ms/step - loss: 0.1772 - accuracy: 0.9376 - val_loss: 0.5896 - val_accuracy: 0.8711\n",
      "Epoch 60/100\n",
      "643/643 [==============================] - 295s 458ms/step - loss: 0.1702 - accuracy: 0.9419 - val_loss: 0.6009 - val_accuracy: 0.8672\n",
      "Epoch 61/100\n",
      "643/643 [==============================] - 294s 457ms/step - loss: 0.1972 - accuracy: 0.9347 - val_loss: 0.6866 - val_accuracy: 0.8602\n",
      "Epoch 62/100\n",
      "643/643 [==============================] - 294s 458ms/step - loss: 0.1829 - accuracy: 0.9317 - val_loss: 0.7398 - val_accuracy: 0.8633\n",
      "Epoch 63/100\n",
      "643/643 [==============================] - 296s 461ms/step - loss: 0.1789 - accuracy: 0.9323 - val_loss: 0.7137 - val_accuracy: 0.8453\n",
      "Epoch 64/100\n",
      "643/643 [==============================] - 291s 453ms/step - loss: 0.1829 - accuracy: 0.9341 - val_loss: 0.7181 - val_accuracy: 0.8609\n",
      "Epoch 65/100\n",
      "643/643 [==============================] - 290s 451ms/step - loss: 0.1773 - accuracy: 0.9385 - val_loss: 0.7332 - val_accuracy: 0.8781\n",
      "Epoch 66/100\n",
      "643/643 [==============================] - 298s 463ms/step - loss: 0.1735 - accuracy: 0.9335 - val_loss: 0.6540 - val_accuracy: 0.8797\n",
      "Epoch 67/100\n",
      "643/643 [==============================] - 299s 464ms/step - loss: 0.1734 - accuracy: 0.9358 - val_loss: 0.5538 - val_accuracy: 0.8672\n",
      "Epoch 68/100\n",
      "643/643 [==============================] - 296s 461ms/step - loss: 0.1687 - accuracy: 0.9362 - val_loss: 0.7979 - val_accuracy: 0.8719\n",
      "Epoch 69/100\n",
      "643/643 [==============================] - 297s 462ms/step - loss: 0.1556 - accuracy: 0.9413 - val_loss: 0.7592 - val_accuracy: 0.8797\n",
      "Epoch 70/100\n",
      "643/643 [==============================] - 297s 462ms/step - loss: 0.1588 - accuracy: 0.9442 - val_loss: 0.8101 - val_accuracy: 0.8750\n",
      "Epoch 71/100\n",
      "643/643 [==============================] - 299s 465ms/step - loss: 0.1720 - accuracy: 0.9370 - val_loss: 0.6395 - val_accuracy: 0.8773\n",
      "Epoch 72/100\n",
      "643/643 [==============================] - 295s 459ms/step - loss: 0.1928 - accuracy: 0.9296 - val_loss: 0.8506 - val_accuracy: 0.8570\n",
      "Epoch 73/100\n",
      "643/643 [==============================] - 300s 466ms/step - loss: 0.1673 - accuracy: 0.9424 - val_loss: 0.6538 - val_accuracy: 0.8687\n",
      "Epoch 74/100\n",
      "643/643 [==============================] - 351s 546ms/step - loss: 0.1440 - accuracy: 0.9487 - val_loss: 0.7279 - val_accuracy: 0.8695\n",
      "Epoch 75/100\n",
      "643/643 [==============================] - 334s 519ms/step - loss: 0.1575 - accuracy: 0.9444 - val_loss: 0.7826 - val_accuracy: 0.8555\n",
      "Epoch 76/100\n",
      "643/643 [==============================] - 326s 507ms/step - loss: 0.1878 - accuracy: 0.9308 - val_loss: 0.7892 - val_accuracy: 0.8500\n",
      "Epoch 77/100\n",
      "643/643 [==============================] - 322s 501ms/step - loss: 0.1665 - accuracy: 0.9385 - val_loss: 0.6627 - val_accuracy: 0.8586\n",
      "Epoch 78/100\n",
      "643/643 [==============================] - 320s 498ms/step - loss: 0.1425 - accuracy: 0.9471 - val_loss: 0.8657 - val_accuracy: 0.8461\n",
      "Epoch 79/100\n",
      "643/643 [==============================] - 303s 471ms/step - loss: 0.1796 - accuracy: 0.9349 - val_loss: 0.5678 - val_accuracy: 0.8859\n",
      "Epoch 80/100\n",
      "643/643 [==============================] - 280s 435ms/step - loss: 0.1670 - accuracy: 0.9382 - val_loss: 0.5438 - val_accuracy: 0.8930\n",
      "Epoch 81/100\n",
      "643/643 [==============================] - 272s 423ms/step - loss: 0.1596 - accuracy: 0.9409 - val_loss: 0.6359 - val_accuracy: 0.8719\n",
      "Epoch 82/100\n",
      "643/643 [==============================] - 282s 439ms/step - loss: 0.1307 - accuracy: 0.9524 - val_loss: 0.7211 - val_accuracy: 0.8734\n",
      "Epoch 83/100\n",
      "643/643 [==============================] - 281s 438ms/step - loss: 0.1476 - accuracy: 0.9438 - val_loss: 0.7051 - val_accuracy: 0.8672\n",
      "Epoch 84/100\n",
      "643/643 [==============================] - 281s 437ms/step - loss: 0.1410 - accuracy: 0.9487 - val_loss: 0.8251 - val_accuracy: 0.8562\n",
      "Epoch 85/100\n",
      "643/643 [==============================] - 278s 432ms/step - loss: 0.1508 - accuracy: 0.9465 - val_loss: 0.8039 - val_accuracy: 0.8633\n",
      "Epoch 86/100\n",
      "643/643 [==============================] - 281s 437ms/step - loss: 0.1613 - accuracy: 0.9446 - val_loss: 0.9214 - val_accuracy: 0.8562\n",
      "Epoch 87/100\n",
      "643/643 [==============================] - 312s 485ms/step - loss: 0.1464 - accuracy: 0.9471 - val_loss: 0.9351 - val_accuracy: 0.8578\n",
      "Epoch 88/100\n",
      "643/643 [==============================] - 317s 493ms/step - loss: 0.1544 - accuracy: 0.9430 - val_loss: 0.6060 - val_accuracy: 0.8836\n",
      "Epoch 89/100\n",
      "643/643 [==============================] - 317s 493ms/step - loss: 0.1418 - accuracy: 0.9477 - val_loss: 0.8726 - val_accuracy: 0.8602\n",
      "Epoch 90/100\n",
      "643/643 [==============================] - 318s 494ms/step - loss: 0.1723 - accuracy: 0.9345 - val_loss: 0.7970 - val_accuracy: 0.8672\n",
      "Epoch 91/100\n",
      "643/643 [==============================] - 317s 494ms/step - loss: 0.1671 - accuracy: 0.9420 - val_loss: 0.6631 - val_accuracy: 0.8711\n",
      "Epoch 92/100\n",
      "643/643 [==============================] - 315s 490ms/step - loss: 0.1471 - accuracy: 0.9469 - val_loss: 0.7265 - val_accuracy: 0.8805\n",
      "Epoch 93/100\n",
      "643/643 [==============================] - 319s 496ms/step - loss: 0.1494 - accuracy: 0.9514 - val_loss: 0.6191 - val_accuracy: 0.8914\n",
      "Epoch 94/100\n",
      "643/643 [==============================] - 326s 507ms/step - loss: 0.1465 - accuracy: 0.9477 - val_loss: 0.8867 - val_accuracy: 0.8648\n",
      "Epoch 95/100\n",
      "643/643 [==============================] - 288s 448ms/step - loss: 0.1450 - accuracy: 0.9469 - val_loss: 0.7064 - val_accuracy: 0.8844\n",
      "Epoch 96/100\n",
      "643/643 [==============================] - 266s 414ms/step - loss: 0.1584 - accuracy: 0.9438 - val_loss: 0.7016 - val_accuracy: 0.8727\n",
      "Epoch 97/100\n",
      "643/643 [==============================] - 266s 414ms/step - loss: 0.1419 - accuracy: 0.9496 - val_loss: 0.7629 - val_accuracy: 0.8805\n",
      "Epoch 98/100\n",
      "643/643 [==============================] - 265s 413ms/step - loss: 0.1478 - accuracy: 0.9436 - val_loss: 0.6223 - val_accuracy: 0.8875\n",
      "Epoch 99/100\n",
      "643/643 [==============================] - 266s 413ms/step - loss: 0.1458 - accuracy: 0.9475 - val_loss: 0.7204 - val_accuracy: 0.8867\n",
      "Epoch 100/100\n",
      "643/643 [==============================] - 265s 412ms/step - loss: 0.1357 - accuracy: 0.9529 - val_loss: 0.7486 - val_accuracy: 0.8836\n",
      "90/90 [==============================] - 30s 330ms/step - loss: 0.2749 - accuracy: 0.9514\n",
      "Test Loss: 0.27491897344589233\n",
      "Test Accuracy: 0.9513888955116272\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained VGG16 model without the top (fully connected) layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
    "\n",
    "# Freeze the weights of the pre-trained layers so they are not updated during training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build the improved CNN model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set the number of training and validation steps per epoch\n",
    "train_steps_per_epoch = train_generator.n // train_generator.batch_size\n",
    "validation_steps_per_epoch = validation_generator.n // validation_generator.batch_size\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    epochs=100,  # Adjust the number of epochs as needed\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps_per_epoch\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_steps_per_epoch = test_generator.n // test_generator.batch_size\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_steps_per_epoch)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b330fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained VGG19 model\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
    "\n",
    "# Freeze the weights of the pre-trained layers so they are not updated during training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build the improved CNN model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set the number of training and validation steps per epoch\n",
    "train_steps_per_epoch = train_generator.n // train_generator.batch_size\n",
    "validation_steps_per_epoch = validation_generator.n // validation_generator.batch_size\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    epochs=50,  # Adjust the number of epochs as needed\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps_per_epoch\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_steps_per_epoch = test_generator.n // test_generator.batch_size\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_steps_per_epoch)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
